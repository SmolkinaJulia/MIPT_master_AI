{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4835b8-b51b-4595-8d1d-b9b64d35d074",
   "metadata": {},
   "source": [
    "# Свертка изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784761e-d11e-4f1b-afe1-bcb053431309",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593feef9-3a80-40ec-aebd-9042c18c3726",
   "metadata": {},
   "source": [
    "## Загрузка изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67329a49-8923-4489-9fd1-14feffd84a7f",
   "metadata": {},
   "source": [
    "Загрузим любое изображение из интернета. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad89f8-cf12-42ec-b0f2-d025a4cc0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hushchyn-mikhail/CourseraDL/main/cnn/screencast_1/butterfly.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704ab04-36a5-4e88-a8a3-1fb3a8ce7f1b",
   "metadata": {},
   "source": [
    "## Чтение изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f3f93-fc0f-4822-a9b8-d024a6bb0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a33569-df9a-49c6-9671-0170eaed434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"butterfly.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c839b-ec87-44b0-a73d-9fb8b3616a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.format, img.size, img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545f713-5af5-4350-9d12-c70e2e6a7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3abb77-47dd-421e-b769-7f144cd45d46",
   "metadata": {},
   "source": [
    "## Матричное представление изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4977015-a114-4896-8f7b-1936e17ad848",
   "metadata": {},
   "source": [
    "Мы знаем, что цветное изображение состоит из 3 числовых матриц или трехмерного тензора. Каждая матрица соответствует одному из 3 базовых цветов: красному, зеленому и синему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ea7fd-9f1f-4236-896c-2ca31fcf8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем тензор\n",
    "img_matrix = np.array(img)\n",
    "\n",
    "#(высота, ширина, каналы)\n",
    "img_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bb978-fccf-4e1c-a68a-72dd93f32a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3287ded-c391-47d5-b867-0d0476514225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_matrix[:, :, 0], cmap=cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img_matrix[:, :, 1], cmap=cm.Greens)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img_matrix[:, :, 2], cmap=cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8bc44-59e4-40e4-a5e0-bae79e59c1c8",
   "metadata": {},
   "source": [
    "# Операция свертки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad02a16-3f33-4857-afd5-a1fcc6af2bb4",
   "metadata": {},
   "source": [
    "В PyTorch свёрточный слой представлен в модуле `nn` функцией [`Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) с параметрами:\n",
    "- количество входных каналов `in_channels`\n",
    "- количество выходных каналов `out_channels`\n",
    "- размер ядра `kernel_size`\n",
    "- шаг `stride`\n",
    "- паддинг `padding`\n",
    "- режим паддинга `padding_mode` (`'zeros'`, `'reflect'` и др.)\n",
    "- `dilation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b713388-e7d4-4be9-b8ac-79fb790f87b1",
   "metadata": {},
   "source": [
    "**Размер ядра** - `int`, если ядро квадратное и кортеж из двух чисел, если ядро прямоугольное. Задает размер фильтра, с которым производится свертка изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee38e4-0c4a-4762-a79d-5f34ee0a27a1",
   "metadata": {},
   "source": [
    "![no_padding_no_strides.gif](no_padding_no_strides.gif)\n",
    "\n",
    "Эта и следующие анимации взяты [здесь](https://github.com/vdumoulin/conv_arithmetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe342c15-c4fe-456f-9083-36e6d8b84515",
   "metadata": {},
   "source": [
    "**Шаг** - задает шаг, в пикселях, на который сдвигается фильтр. `int`, если по горизонтали и вертикали сдвигается на одно и то же число. Кортеж из двух чисел, если сдвиги разные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f61ba-9c13-4906-9f6d-184764380109",
   "metadata": {},
   "source": [
    "![no_padding_strides.gif](no_padding_strides.gif)\n",
    "\n",
    "Шаг: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916cd953-9e60-44b1-9d73-cc06f24b29f3",
   "metadata": {},
   "source": [
    "**Паддинг** - количество пикселей, которыми дополняется изображение. Аналогично шагу и размеру ядра, может быть, как `int`, так и кортежем из двух чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e7794-1f20-4e8b-b046-ccba2bd6d0c5",
   "metadata": {},
   "source": [
    "**Half pading**\n",
    "![same_padding_no_strides.gif](same_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11369f-cbd6-4108-bd9e-1cc9aaf2afdc",
   "metadata": {},
   "source": [
    "# Свертка изображения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd57a8-c37e-4d85-ab95-1e7eb9ecc1ac",
   "metadata": {},
   "source": [
    "Применим оператор Собеля для детектирования границ на изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b46e2-e085-4bd0-b011-f3ef8325ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089cd56-2b90-461b-b3bc-ae0fdbd26c17",
   "metadata": {},
   "source": [
    "Конвертируем изображение в нужный формат для PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f65a8-61cb-4a0c-9444-0fd19710c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.tensor([img_matrix], dtype=torch.float)\n",
    "img_tensor.size() #(число изображений, высота, ширина, число каналов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f42600-e132-40ac-8aea-2e7dd096b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = img_tensor.permute(0, 3, 1, 2)\n",
    "img_tensor.size() #(число изображений, число каналов, высота, ширина)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0c21f-4ebb-4387-bd11-6623aab7c516",
   "metadata": {},
   "source": [
    "Зададим оператор Собеля для детектирования горизонтальных границ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9d84e-8232-4c96-a1a8-734905d731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_hor = [[-1, -2, -1], \n",
    "             [ 0,  0,  0], \n",
    "             [ 1,  2,  1]]\n",
    "\n",
    "# одна матрица на каждый канал картинки\n",
    "kernel  = [[sobel_hor, sobel_hor, sobel_hor]]\n",
    "kernel = torch.tensor(kernel, dtype=torch.float)\n",
    "kernel.size() #(число выходных каналов, число входных каналов, высота, ширина)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10771b7f-4044-4a19-99b0-8e87aad41b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_conv_hor = conv2d(img_tensor, kernel)\n",
    "\n",
    "img_conv_hor = img_conv_hor.permute(0, 2, 3, 1)\n",
    "img_conv_hor.size() #(число изображений, высота, ширина, число каналов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85348606-7d56-42c4-81cf-b24956264450",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.5*7, 1.5*4))\n",
    "plt.imshow(torch.abs(img_conv_hor[0, :, :, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b2aca-9560-47d4-846a-d7cd38f38752",
   "metadata": {},
   "source": [
    "Зададим оператор Собеля для детектирования вертикальных границ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b08997-3e0e-4065-9681-14f03eab1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_ver = [[-1, 0, 1], \n",
    "             [-2, 0, 2], \n",
    "             [-1, 0, 1]]\n",
    "\n",
    "# одна матрица на каждый канал картинки\n",
    "kernel  = [[sobel_ver, sobel_ver, sobel_ver]]\n",
    "kernel = torch.tensor(kernel, dtype=torch.float)\n",
    "kernel.size() #(число выходных каналов, число входных каналов, высота, ширина)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453672f6-3a2e-4acd-8ca9-d230f17361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_conv_ver = conv2d(img_tensor, kernel)\n",
    "\n",
    "img_conv_ver = img_conv_ver.permute(0, 2, 3, 1)\n",
    "img_conv_ver.size() #(число изображений, высота, ширина, число каналов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3679a-9d64-4a36-8adc-d99a65dd0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.5*7, 1.5*4))\n",
    "plt.imshow(torch.abs(img_conv_ver[0, :, :, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89dcdeb-4c93-4d93-b8e8-058519d744be",
   "metadata": {},
   "source": [
    "Объединим два изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a710690-b92f-44c8-8e75-98da874cc00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_conv = torch.sqrt(img_conv_ver**2 + img_conv_hor**2)\n",
    "\n",
    "plt.figure(figsize=(1.5*7, 1.5*4))\n",
    "plt.imshow(img_conv[0, :, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3a48c-3301-4748-8eb4-c089ce2827da",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "По аналогии с примером выше, сверните изображение со случайным ядром такого же размера.\n",
    "\n",
    "**Подсказка:** используйте `torch.rand()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e4afa-590d-4381-b6cc-e162a90b11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here\n",
    "kernel = ...\n",
    "### the end\n",
    "\n",
    "# свертка изображения\n",
    "img_conv_ver = conv2d(img_tensor, kernel)\n",
    "img_conv_ver = img_conv_ver.permute(0, 2, 3, 1)\n",
    "\n",
    "# рисуем результат\n",
    "plt.figure(figsize=(1.5*7, 1.5*4))\n",
    "plt.imshow(torch.abs(img_conv_ver[0, :, :, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5920aa-aebe-4949-9a3b-1ad321964ac8",
   "metadata": {},
   "source": [
    "# Полносвязная нейронная сеть\n",
    "\n",
    "Решим задачу классификации изображений полносвзяной нейронной сетью из прошлого семинара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d617493-ceee-4cd0-9f07-698e12b8aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2cec5c-74c8-40e7-a168-85d4ebcac601",
   "metadata": {},
   "source": [
    "Скачаем и подготовим данные для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32183abc-1017-4a63-8ef5-1abd34159a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d327368-5817-4dd2-9bc2-b23238d60398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем готовый класс от торча для загрузки данных для тренировки\n",
    "mnist_train = torchvision.datasets.MNIST('./mnist/', train=True, download=True, transform=transform)\n",
    "\n",
    "# используем готовый класс от торча для загрузки данных для валидации\n",
    "mnist_val = torchvision.datasets.MNIST('./mnist/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85983b9d-40df-4102-8275-8f9c1e40c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "\n",
    "# так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb296c-babe-4d76-a458-fdce6936cdb3",
   "metadata": {},
   "source": [
    "Пример изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ca9ad-2e21-4ba5-9369-a238d8a88d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(mnist_train[i][0].squeeze(0).numpy().reshape([28, 28]))\n",
    "    plt.title(str(mnist_train[i][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f78c61-d771-439d-a0ea-8837df8359cc",
   "metadata": {},
   "source": [
    "Обучаем полносвязную нейронную сеть для классификации изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b05b6-5eac-4300-afa6-029020548836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(), # превращаем картинку 28х28 в вектор размером 784\n",
    "    nn.Linear(784, 128), # входной слой размером 784 нейронов с выходом в 128 нейронов\n",
    "    nn.ReLU(), # функция активации релу\n",
    "    nn.Linear(128, 10), # функция активации релу\n",
    "    nn.Softmax(dim=-1) # софтмакс для получения вероятностного распределения над метками класса\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # создаем оптимизатор и передаем туда параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e3c2d-f777-4453-aecb-8e9e409607dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    epoch = 0\n",
    "    for epoch in range(0,11): # всего у нас будет 10 эпох (10 раз подряд пройдемся по всем батчам из трейна)\n",
    "        for x_train, y_train in tqdm(train_dataloader): # берем батч из трейн лоадера\n",
    "            y_pred = model(x_train) # делаем предсказания\n",
    "            loss = nn.CrossEntropyLoss()(y_pred, y_train) # считаем лосс\n",
    "            loss.backward() # считаем градиенты обратным проходом\n",
    "            optimizer.step() # обновляем параметры сети\n",
    "            optimizer.zero_grad() # обнуляем посчитанные градиенты параметров\n",
    "\n",
    "        # валидация\n",
    "        mean_val_loss = [] # сюда будем складывать средний лосс по батчам\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad(): # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(val_dataloader): # берем батч из вал лоадера\n",
    "                y_pred = model(x_val) # делаем предсказания\n",
    "                loss = nn.CrossEntropyLoss()(y_pred, y_val) # считаем лосс\n",
    "                mean_val_loss.append(loss.numpy()) # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "        print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "        )) # выводим статистику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e275745-5519-452d-8694-f0e435574e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd98b7-2102-4e20-a8fd-6f55e85c2e23",
   "metadata": {},
   "source": [
    "# Сверточный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e3694-c22b-430e-9807-92ba2314a94a",
   "metadata": {},
   "source": [
    "Добавим в нашу сеть сверточный слой. Обратите внимание на то, как изменится качество классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d3744-652e-42e6-9164-57e264a58059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5), # добавим сверточный слой с 10 ядрами\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(4), # уменьшим картинку в 4 раза\n",
    "    nn.Flatten(), # превращаем картинку 6х6х10 в вектор размером 360\n",
    "    nn.Linear(6*6*10, 128), # входной слой размером 360 нейронов с выходом в 128 нейронов\n",
    "    nn.ReLU(), # функция активации релу\n",
    "    nn.Linear(128, 10), # функция активации релу\n",
    "    nn.Softmax(dim=-1) # софтмакс для получения вероятностного распределения над метками класса\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # создаем оптимизатор и передаем туда параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769f454-4443-4ce6-86fd-2cd6b79a1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3593a4c-cce8-45f1-8c2c-e4f590191058",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "По аналогии с предыдущим примером, обучите нейронную сеть, у которой следущие слои:\n",
    "\n",
    "- Сверточный слой с 10 ядрами размером 5\n",
    "- Функция активации ReLU\n",
    "- Уменьшить картинку в 2 раза (по каждому измерению)\n",
    "- Сверточный слой с 20 ядрами размером 5\n",
    "- Функция активации ReLU\n",
    "- Уменьшить картинку в 2 раза (по каждому измерению)\n",
    "- Полносвязный слой со 128 нейронами\n",
    "- Функция активации ReLU\n",
    "- Выходной слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f5019-a4a1-44f1-a098-13afa75da817",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here\n",
    "model = ...\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # создаем оптимизатор и передаем туда параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec4811-766c-4afb-baf0-5131d9583e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9bf70d-fc52-49e5-9cbe-72ecd896b7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292fb93-7ea0-472f-a84c-5be11d7756a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
